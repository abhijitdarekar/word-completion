{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329ec6e1-4fc5-4fa1-802b-db0f10480bed",
   "metadata": {},
   "source": [
    "## Kneser Ney Method for next word prediction"
   ]
  },
  {
   "attachments": {
    "89328678-f4ef-4a10-81ed-e0eedc897821.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "17d7e290-0068-4546-84bb-2260e133833e",
   "metadata": {},
   "source": [
    "Kneser-Ney is a method primarily used to calculate the probability distribution of n-grams in a document based on their counts/histories in document.\n",
    "\n",
    "\n",
    "#### Method\n",
    "\n",
    "\n",
    "![image.png](attachment:89328678-f4ef-4a10-81ed-e0eedc897821.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Where , `w` and `w'` are word followed by each other in corus.<br>\n",
    "`delta` is a discounting factor.(Which can be tuned.)-1}}}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fc101e80-51b3-4c87-9a3d-d3a6adec7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict,defaultdict\n",
    "from nltk.util import ngrams\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b2f0535f-28a0-4aaa-ac14-527d42ee341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conf:\n",
    "    punctuations = '!\"#$%&\\()*+,-./:;=?@[\\\\]^_`{|}~'\n",
    "    ngramLowerOrder = 2\n",
    "    ngramHigherOrder = 6\n",
    "    d = 0.75\n",
    "    interpolation  = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8d584290-eee2-4f02-96cf-282f84d253ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(data,n,vocab_dict):\n",
    "    ngram_dict = defaultdict(int)\n",
    "    lines = data\n",
    "    \n",
    "    lines = ['<start> ' + x + ' <end>' for x in lines]\n",
    "    for line in lines:\n",
    "        temp_l = line.split()\n",
    "        # print(temp_l)\n",
    "        i = 0\n",
    "        j = 0\n",
    "        for word in temp_l :\n",
    "            j = 0\n",
    "            for l in word :\n",
    "                if l in '!\"#$%&\\'()*+,-./:;=?@[\\\\]^_`{|}~':\n",
    "                    if l == \"'\":\n",
    "                        if j+1<len(word) and word[j+1] == 's':\n",
    "                            j = j + 1\n",
    "                            continue\n",
    "                    word = word.replace(l,\" \")\n",
    "                    #print(j,word[j])\n",
    "                j += 1\n",
    "            temp_l[i] = word.lower()\n",
    "            i=i+1 \n",
    "        content = \" \".join(temp_l)\n",
    "        token = content.split()\n",
    "        if not token:\n",
    "            continue\n",
    "        ngrams_list = list(ngrams(token, n))\n",
    "        # Building Vocabulary\n",
    "        for word in token:\n",
    "            if word not in vocab_dict.keys():\n",
    "                vocab_dict[word] = 1\n",
    "            else:\n",
    "                vocab_dict[word] += 1\n",
    "        # Building Ngram\n",
    "        if ngrams_list == []:\n",
    "            pass\n",
    "        else:\n",
    "            for t in ngrams_list:\n",
    "                sen = ' '.join(t)\n",
    "                ngram_dict[sen] += 1\n",
    "    return ngram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "638eef86-edec-4c6c-8c19-42126e240ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kneser_ney_dict(ngram_dict, n):\n",
    "    first_dict = {}\n",
    "    sec_dict = {}\n",
    "    for key in ngram_dict:\n",
    "        ngram_token = key.split()\n",
    "        n_1gram_sen = ' '.join(ngram_token[:n-1])\n",
    "        if n_1gram_sen not in sec_dict:\n",
    "            sec_dict[ n_1gram_sen ] = 1\n",
    "        else:\n",
    "            sec_dict[ n_1gram_sen ] += 1\n",
    "            \n",
    "        if ngram_token[-1] not in first_dict:\n",
    "            first_dict[ ngram_token[-1] ] = 1\n",
    "        else:\n",
    "            first_dict[ ngram_token[-1] ] += 1\n",
    "    \n",
    "    return first_dict, sec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f3a464a8-bf45-4478-a14f-ee2e8fe978ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeKnesserNeyProb2(ngram_dicts,vocab_dict,prob_dict):\n",
    "    d = 0.75\n",
    "    interpolation = 0.4\n",
    "    for order in range(2, len(ngram_dicts) + 2):\n",
    "        current_dict = ngram_dicts[order - 2]\n",
    "\n",
    "        first_dict, sec_dict = create_kneser_ney_dict(current_dict, order)\n",
    "\n",
    "        for ngram in current_dict:\n",
    "            ngram_tokens = ngram.split()\n",
    "            prefix = ' '.join(ngram_tokens[:-1])\n",
    "            if prefix not in sec_dict:\n",
    "                # Use lower-order n-gram probabilities as back-off\n",
    "                prob_dict[prefix] = prob_dict.get(prefix, [])\n",
    "                prob_dict[prefix].append([interpolation * vocab_dict[ngram_tokens[-1]] / sum(vocab_dict.values()), ngram_tokens[-1]])\n",
    "                continue\n",
    "\n",
    "            prob1 = max(current_dict[ngram] - d, 0) / sec_dict[prefix] if prefix in sec_dict else 0\n",
    "            prob2 = d / sec_dict[prefix] * (first_dict[ngram_tokens[-1]] if ngram_tokens[-1] in first_dict else 0)\n",
    "\n",
    "            for i in range(order - 2, 0, -1):\n",
    "                ngram_prefix = ' '.join(ngram_tokens[i:-1])\n",
    "                prob2 *= d / len(ngram_dicts[i - 1]) * (sec_dict[ngram_prefix] if ngram_prefix in sec_dict else 0)\n",
    "\n",
    "            prob_dict[prefix] = prob_dict.get(prefix, [])\n",
    "#             prob_dict[prefix].append([prob1 + prob2, ngram_tokens[-1]])\n",
    "            prob_dict[prefix].append([(1 - interpolation) * (prob1 + prob2) + interpolation * vocab_dict[ngram_tokens[-1]] / sum(vocab_dict.values()), ngram_tokens[-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ff7d938e-32aa-4819-9ae2-dc7074fa251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_prob_word_wict(prob_dict):\n",
    "    for key in prob_dict.keys():\n",
    "        if len(prob_dict[key])>0:\n",
    "            prob_dict[key] = sorted(prob_dict[key],reverse = True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e8fdcea2-0bda-4b48-a8a5-28c3e04fbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input(sen):\n",
    "    temp_l = sen.split()\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for word in temp_l:\n",
    "        for l in word :\n",
    "            if l in '!\"#$%&\\'()*+,-./:;=?@[\\\\]^_`{|}~':\n",
    "                if l == \"'\":\n",
    "                    if j+1<len(word) and word[j+1] == 's':\n",
    "                        j = j + 1\n",
    "                        continue\n",
    "                word = word.replace(l,\" \")\n",
    "            j += 1\n",
    "\n",
    "        temp_l[i] = word.lower()\n",
    "        i=i+1   \n",
    "    content = \" \".join(temp_l)\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "689048a0-5191-4901-914b-da5cc52abc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(sen,prob_dict):\n",
    "    n = len(sen.split(\" \"))\n",
    "    sen = sen.split()\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        a =  \" \".join(sen[i:])\n",
    "        if a in prob_dict:\n",
    "            return prob_dict[a]\n",
    "        \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1830a6ab-3adb-43c1-be34-05a49f524be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Computing Ngrams --\n",
      "Completed\n",
      "-- Computing Kneser Ney Probablites --\n",
      "-- Sorting Proabblities --\n"
     ]
    }
   ],
   "source": [
    "data = [x.strip() for x in open(\"../data/movie.txt\").readlines()]\n",
    "conf = Conf()\n",
    "vocab_dict = defaultdict(int)\n",
    "conf.ngramLowerOrder = 2\n",
    "conf.ngramHigherOrder = 10\n",
    "ngram_dicts = []\n",
    "for i in range(conf.ngramLowerOrder,conf.ngramHigherOrder):\n",
    "    ngram_dicts.append(load_corpus(data,i,vocab_dict))\n",
    "print(\"-- Computing Ngrams --\")\n",
    "prob_dict = OrderedDict()\n",
    "computeKnesserNeyProb2(ngram_dicts, vocab_dict,prob_dict)\n",
    "print(\"-- Computing Kneser Ney Probablites --\")\n",
    "sort_prob_word_wict(prob_dict)\n",
    "print(\"-- Sorting Proabblities --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5f041839-ed7b-4df7-8f84-8829b70343d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the sentence to predict :  can we\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : can we go\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the sentence to predict :  are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : are you sure\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the sentence to predict :  Hello\n",
      "Enter the sentence to predict :  GOod\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : good morning\n",
      "Predicted : good luck\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the sentence to predict :  exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    inp = input(\"Enter the sentence to predict : \")\n",
    "    max_len= 5\n",
    "    if inp.split() == [] and len(inp.split())>0:\n",
    "        break\n",
    "    if inp == \"exit\": \n",
    "        break\n",
    "    inp = clean_input(inp)\n",
    "    inp = f\"<start> {inp}\" \n",
    "    final_words = predict_word(inp,prob_dict)\n",
    "    max = 0\n",
    "    for words in final_words:\n",
    "        if words[0]>0.1:\n",
    "            print('Predicted :',inp.replace(\"<start>\",\"\").strip(),words[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
